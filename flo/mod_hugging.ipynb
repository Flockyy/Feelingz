{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d128d59565d2101c\n",
      "Reusing dataset csv (C:\\Users\\Apprenant\\.cache\\huggingface\\datasets\\csv\\default-d128d59565d2101c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ea38a3b386427d8b2afc37244bd50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train' : '../data/kaggle_train.csv', 'test' : '../data/kaggle_test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition/resolve/main/preprocessor_config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\2f11b5e35aba5d2158c09cc5e26f39d0ac8b363cfd8c169b57bf4121eca30135.bbc1eb890a39c82e710a893223b8452ac5b78e8b57083b2f893aa7dc59d4ed69\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/preprocessor_config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\f617824bfb14cf31abf77325931c53d6b436d6f8c7f7ff45db350bfbb823d23e.064f1706c059d3c7e3874f91b9eb5fd0eec17664990fd798168496eb0b4e1445\n",
      "loading configuration file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\882f0cab8dbb456e5b1d6e3b96e864be0cb6c2bc5d20ee88eeda10b3c0317332.a3f80b6502f00efe74a01c6a007f196803229a24224659c81c1da7c4cf5316e8\n",
      "Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutlmv2-base-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"fast_qkv\": true,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": true,\n",
      "  \"has_spatial_attention_bias\": true,\n",
      "  \"has_visual_segment_embedding\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/preprocessor_config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\f617824bfb14cf31abf77325931c53d6b436d6f8c7f7ff45db350bfbb823d23e.064f1706c059d3c7e3874f91b9eb5fd0eec17664990fd798168496eb0b4e1445\n",
      "Feature extractor LayoutLMv2FeatureExtractor {\n",
      "  \"apply_ocr\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"size\": 224\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\d89c2d629941dc87c135811ea31266296eb295f0f1a84ae433c73dcbe863e03d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\882f0cab8dbb456e5b1d6e3b96e864be0cb6c2bc5d20ee88eeda10b3c0317332.a3f80b6502f00efe74a01c6a007f196803229a24224659c81c1da7c4cf5316e8\n",
      "Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutlmv2-base-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"fast_qkv\": true,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": true,\n",
      "  \"has_spatial_attention_bias\": true,\n",
      "  \"has_visual_segment_embedding\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\882f0cab8dbb456e5b1d6e3b96e864be0cb6c2bc5d20ee88eeda10b3c0317332.a3f80b6502f00efe74a01c6a007f196803229a24224659c81c1da7c4cf5316e8\n",
      "Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutlmv2-base-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"fast_qkv\": true,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": true,\n",
      "  \"has_spatial_attention_bias\": true,\n",
      "  \"has_visual_segment_embedding\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoProcessor, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Apprenant\\.cache\\huggingface\\datasets\\csv\\default-d128d59565d2101c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-511d4efe102e4efc.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Apprenant\\.cache\\huggingface\\datasets\\csv\\default-d128d59565d2101c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-d7e11e442a668431.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'feelings', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 17167\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['content', 'feelings', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4292\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Apprenant\\.cache\\huggingface\\datasets\\csv\\default-d128d59565d2101c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-84f3a7f45763ce27.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Apprenant\\.cache\\huggingface\\datasets\\csv\\default-d128d59565d2101c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-d795c9ec1f2d7b6c.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=small_train_dataset,\n",
    "#     eval_dataset=small_eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = small_train_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"target\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "tf_validation_dataset = small_eval_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"target\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/tf_model.h5 from cache at C:\\Users\\Apprenant/.cache\\huggingface\\transformers\\01800f4158e284e2447020e0124bc3f6aea3ac49848e744594f7cce8ee5ac0a4.a7137b2090d9302d722735af604b4c142ec9d1bfc31be7cbbe230aea9d5cfb76.h5\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 11/125 [=>............................] - ETA: 36:35 - loss: 1.5963 - sparse_categorical_accuracy: 0.2500"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_for_sequence_classification_1/bert/embeddings/Gather' defined at (most recent call last):\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Apprenant\\AppData\\Local\\Temp\\ipykernel_15460\\475021319.py\", line 7, in <module>\n      model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 996, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1619, in run_call_with_unpacked_inputs\n      >>> model = TFBertModel.from_pretrained(\"./test/saved_model/\")\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1633, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1619, in run_call_with_unpacked_inputs\n      >>> model = TFBertModel.from_pretrained(\"./test/saved_model/\")\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 768, in call\n      embedding_output = self.embeddings(\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 189, in call\n      if input_ids is not None:\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 190, in call\n      inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\nNode: 'tf_bert_for_sequence_classification_1/bert/embeddings/Gather'\nindices[4,4] = 29118 is not in [0, 28996)\n\t [[{{node tf_bert_for_sequence_classification_1/bert/embeddings/Gather}}]] [Op:__inference_train_function_38413]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Apprenant\\Desktop\\Feelingz\\flo\\mod_hugging.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Apprenant/Desktop/Feelingz/flo/mod_hugging.ipynb#ch0000024?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Apprenant/Desktop/Feelingz/flo/mod_hugging.ipynb#ch0000024?line=1'>2</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m5e-5\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Apprenant/Desktop/Feelingz/flo/mod_hugging.ipynb#ch0000024?line=2'>3</a>\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Apprenant/Desktop/Feelingz/flo/mod_hugging.ipynb#ch0000024?line=3'>4</a>\u001b[0m     metrics\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mSparseCategoricalAccuracy(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Apprenant/Desktop/Feelingz/flo/mod_hugging.ipynb#ch0000024?line=4'>5</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Apprenant/Desktop/Feelingz/flo/mod_hugging.ipynb#ch0000024?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(tf_train_dataset, validation_data\u001b[39m=\u001b[39;49mtf_validation_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/Apprenant/anaconda3/envs/datascience/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bert_for_sequence_classification_1/bert/embeddings/Gather' defined at (most recent call last):\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Apprenant\\AppData\\Local\\Temp\\ipykernel_15460\\475021319.py\", line 7, in <module>\n      model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 996, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1619, in run_call_with_unpacked_inputs\n      >>> model = TFBertModel.from_pretrained(\"./test/saved_model/\")\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1633, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1619, in run_call_with_unpacked_inputs\n      >>> model = TFBertModel.from_pretrained(\"./test/saved_model/\")\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 768, in call\n      embedding_output = self.embeddings(\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 189, in call\n      if input_ids is not None:\n    File \"C:\\Users\\Apprenant\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 190, in call\n      inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\nNode: 'tf_bert_for_sequence_classification_1/bert/embeddings/Gather'\nindices[4,4] = 29118 is not in [0, 28996)\n\t [[{{node tf_bert_for_sequence_classification_1/bert/embeddings/Gather}}]] [Op:__inference_train_function_38413]"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a86bb9999e185c5eb4718a1126b266a576153fe71177607b62eca8ed5e27b4d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
